from typing import Literal,TypedDict
from LLMs.azure_models import large_azure_llm, gpt_oss_llm
from langgraph.graph import StateGraph, END
from typing import Dict, Any
from langchain_core.prompts import ChatPromptTemplate
from pydantic import Field, BaseModel
from langchain.output_parsers import PydanticOutputParser, OutputFixingParser



class orchestratorOutput(BaseModel):
    message: str = Field(..., description="The message from the agent. (ok if there is no problem and error if there is)")
    next_step: Literal['query_planner', 'analyser', "end"] = Field(..., description="The next agent to handle the task: Query Planner, Behavior Analyst, or end if the task is complete.")
    
system_prompt = """
You are the Orchestrator, the central decision-maker in a data analysis pipeline.
Your mission is to evaluate the task's current state and route it to the next logical step to answer a user's request.

You will receive the following context:
- user_request: The user's original question.
- data_acquired: The data retrieved so far.
- analysis: The insights generated from the data.
- sender: The agent that provided the last message.
- message: The content of the last message.

### Your Decision-Making Logic (Evaluate in this strict order)

1.  **Check for Stalled Progress / Loop Detection:**
    - **Condition:** If the `sender` is 'analyser' requesting data, BUT that data has already been requested (check `data_acquired` or `steps`), OR if the conversation is going in circles without new data appearing.
    - **Action:** Route to `analyser`. Message: "Data unavailable or request repeated. Finalize analysis with current data."

2.  **Check for analyser's Explicit Request for Data:**
    - **Condition:** If the `sender` is 'analyser' AND its `message` clearly states that more information or data is required to proceed.
    - **Action:** Immediately route to `query_planner`. Your message to the planner should be based on the analyser's specific request.

3.  **Assess Analysis Quality:**
    - **Condition:** If the `data_acquired` IS sufficient, but the `analysis` is superficial, lacks behavioral insights (e.g., "why" the spending happened), or does not address the `user_request`.
    - **Action:** Route to `analyser`. Message: "Analysis is too descriptive. Please provide deeper behavioral insights or psychological context (e.g., emotional spending, habits)."

4.  **Determine Task Completion:**
    - **Condition:** If the data is sufficient AND the analysis is high-quality and directly answers the `user_request`.
    - **Action:** Route to `end`. Your message should be a final confirmation.

### Output Format
You MUST respond with a single, valid JSON object:
{{
    "next_step": "query_planner | analyser | end",
    "message": "A clear, concise message or instruction for the next step."
}}
"""

user_prompt = """
Current Task State:
- Current Date: {current_date}
- User Request: {request}
- Data Acquired by database agent: {data_acquired}
- Analysis Done by the analyser: {analysis}
- steps generated by query planner till now: {steps}
- messages from the workflow:
{message}

Based on the current state, decide the next step.
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("user", user_prompt)
])

Behaviour_analyser_orchestrator = prompt | gpt_oss_llm.with_structured_output(orchestratorOutput)