from typing import Literal
from core.llm_providers.digital_ocean import gpt_oss_120b_digital_ocean
from langchain_core.prompts import ChatPromptTemplate
from pydantic import Field, BaseModel
from langchain_core.messages import BaseMessage
import json

class orchestratorOutput(BaseModel):
    message: str = Field(..., description="The message from the agent. (ok if there is no problem and error if there is)")
    next_step: Literal['query_planner', 'analyser', "end"] = Field(..., description="The next agent to handle the task: Query Planner, Behavior Analyst, or end if the task is complete.")
    
system_prompt = """
You are the Orchestrator. Route tasks based on the current state.

### GLOBAL SCOPE (STRICT)
- **CURRENT DATA ONLY**: If the user asks for "this month" or "now", FETCH ONLY THAT MONTH. 
- **NO HISTORICAL/TRENDS**: Do NOT ask for "previous months", "last 3 months", "comparison" UNLESS explicitly requested.
- **NO SQL**: Never write SQL.

### DECISION LOGIC (IF -> THEN)

| IF this Condition is Met | THEN do this Action | Message to Send |
| :--- | :--- | :--- |
| `sender` == 'analyser' requesting specific data (e.g., "FETCH: x") | Route to `query_planner` | Repeat the request exactly (e.g., "Retrieve x"). |
| `sender` == 'analyser' says "DONE" or "Analysis complete" | Route to `end` | "Analysis finalized." |
| `data_acquired` is empty/null/zero | Route to `analyser` | "No data found. Inform the user." (DO NOT RETRY) |
| Conversation is looping / Stalled | Route to `analyser` | "Stalled. Finalize with current data." |
| Default Case (Start or Analysis needs check) | Route to `analyser` | "Analyze the current data." |

### Output Format
{{
    "next_step": "query_planner | analyser | end",
    "message": "Clear instruction."
}}
"""

user_prompt = """
Current Task State:
- Current Date: {current_date}
- User Request: {request}
- Data Acquired by database agent: {data_acquired}
- Analysis Done by the analyser: {analysis}
- steps generated by query planner till now: {steps}
- messages from the workflow:
{message}

Based on the current state, decide the next step.
"""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    ("user", user_prompt)
])

def parse_output(message: BaseMessage | str) -> orchestratorOutput | None:
    text = message.content if isinstance(message, BaseMessage) else message
    text = text.replace("```json", "").replace("```", "").strip()
    try:
        data = json.loads(text)
        return orchestratorOutput(**data)
    except Exception as e:
        print(f"Parsing error: {e}")
        print(f"Raw Output: {text}")
        return None  

Behaviour_analyser_orchestrator = prompt | gpt_oss_120b_digital_ocean | parse_output
